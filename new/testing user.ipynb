{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05617949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2022-02-28 14:16:33.476677: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-28 14:16:33.476955: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "finished recording\n",
      "Recognized as -  Bhavya Sri\n",
      "Keep Your face infront of the camera\n",
      "Not Recognized! Try again...\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from scipy.io.wavfile import read\n",
    "from IPython.display import Audio, display, clear_output\n",
    "\n",
    "from main_functions import *\n",
    "\n",
    "def recognize():\n",
    "    # Voice Authentication\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 4\n",
    "    FILENAME = \"test.wav\"\n",
    "\n",
    "    audio = pyaudio.PyAudio()\n",
    "   \n",
    "    # start Recording\n",
    "    stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "    time.sleep(2.0)\n",
    "    print(\"recording...\")\n",
    "    frames = []\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK,exception_on_overflow = False)\n",
    "        frames.append(data)\n",
    "    print(\"finished recording\")\n",
    "\n",
    "\n",
    "    # stop Recording\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # saving wav file \n",
    "    waveFile = wave.open(FILENAME, 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "\n",
    "    modelpath = \"./gmm_models/\"\n",
    "\n",
    "    gmm_files = [os.path.join(modelpath,fname) for fname in \n",
    "                os.listdir(modelpath) if fname.endswith('.gmm')]\n",
    "\n",
    "    models    = [pickle.load(open(fname,'rb')) for fname in gmm_files]\n",
    "\n",
    "    speakers   = [fname.split(\"/\")[-1].split(\".gmm\")[0] for fname \n",
    "                in gmm_files]\n",
    "  \n",
    "    if len(models) == 0:\n",
    "        print(\"No Users in the Database!\")\n",
    "        return\n",
    "        \n",
    "    #read test file\n",
    "    sr,audio = read(FILENAME)\n",
    "\n",
    "    # extract mfcc features\n",
    "    vector = extract_features(audio,sr)\n",
    "    log_likelihood = np.zeros(len(models)) \n",
    "\n",
    "    #checking with each model one by one\n",
    "    for i in range(len(models)):\n",
    "        gmm = models[i]         \n",
    "        scores = np.array(gmm.score(vector))\n",
    "        log_likelihood[i] = scores.sum()\n",
    "\n",
    "    pred = np.argmax(log_likelihood)\n",
    "    identity = speakers[pred]\n",
    "   \n",
    "    # if voice not recognized than terminate the process\n",
    "    if identity == 'unknown':\n",
    "            print(\"Not Recognized! Try again...\")\n",
    "            return\n",
    "    \n",
    "    print( \"Recognized as - \", identity)\n",
    "\n",
    "    # face recognition\n",
    "    print(\"Keep Your face infront of the camera\")\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 640)\n",
    "    cap.set(4, 480)\n",
    "\n",
    "    cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    #loading the database \n",
    "    database = pickle.load(open('embeddings.pickle', \"rb\"))\n",
    "    \n",
    "    time.sleep(1.0)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    while True:\n",
    "        curr_time = time.time()\n",
    "            \n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        face = cascade.detectMultiScale(gray, 1.3, 5)\n",
    "         \n",
    "        name = 'unknown'\n",
    "        \n",
    "        \n",
    "        if len(face) == 1:\n",
    "\n",
    "            for (x, y, w, h) in face:\n",
    "                roi = frame[y-10:y+h+10, x-10:x+w+10]\n",
    "            \n",
    "                fh, fw = roi.shape[:2]\n",
    "                min_dist = 100\n",
    "                \n",
    "                #make sure the face is of required height and width\n",
    "                if fh < 20 and fh < 20:\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                #resizing image as required by the model\n",
    "                img = cv2.resize(roi, (96, 96))\n",
    "\n",
    "                #128 d encodings from pre-trained model\n",
    "                encoding = img_to_encoding(img)\n",
    "                \n",
    "                # loop over all the recorded encodings in database \n",
    "                for knownName in database:\n",
    "                    # find the similarity between the input encodings and recorded encodings in database using L2 norm\n",
    "                    dist = np.linalg.norm(np.subtract(database[knownName], encoding) )\n",
    "                    # check if minimum distance or not\n",
    "                    if dist < min_dist:\n",
    "                        min_dist = dist\n",
    "                        name = knownName\n",
    "\n",
    "            # if min dist is less then threshold value and face and voice matched than unlock the door\n",
    "            if min_dist <= 0.4 and name == identity:\n",
    "                print (\"Door Unlocked! Welcome \" + str(name))\n",
    "                break\n",
    "\n",
    "        #open the cam for 3 seconds\n",
    "        if curr_time - start_time >= 3:\n",
    "            break    \n",
    "\n",
    "        cv2.waitKey(1)\n",
    "        cv2.imshow('frame', frame)\n",
    "        \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "   \n",
    "    if len(face) == 0:\n",
    "        print('There was no face found in the frame. Try again...')\n",
    "        \n",
    "    elif len(face) > 1:\n",
    "        print(\"More than one faces found. Try again...\")\n",
    "        \n",
    "    elif min_dist > 0.4 or name != identity:\n",
    "        print(\"Not Recognized! Try again...\")\n",
    "   \n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    recognize()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
