{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b3cfd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2022-02-28 14:13:58.176358: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-02-28 14:13:58.176626: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Name:Bhavya\n",
      "\u001b[H\u001b[2J\u001b[H\u001b[2JSpeak your name in 3 seconds\n",
      "\u001b[H\u001b[2JSpeak your name in 2 seconds\n",
      "\u001b[H\u001b[2JSpeak your name in 1 seconds\n",
      "\u001b[H\u001b[2JSpeak your name in 0 seconds\n",
      "recording...\n",
      "Done\n",
      "Speak your name one more time\n",
      "recording...\n",
      "Done\n",
      "Speak your name one last time\n",
      "recording...\n",
      "Done\n",
      "Bhavya added successfully\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import cv2\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from scipy.io.wavfile import read\n",
    "from IPython.display import Audio, display, clear_output\n",
    "\n",
    "from main_functions import *\n",
    "\n",
    "def add_user():\n",
    "    \n",
    "    name = input(\"Enter Name:\")\n",
    "\n",
    "     # check for existing database\n",
    "    if os.path.exists('embeddings.pickle'):\n",
    "        with open('embeddings.pickle', 'rb') as database:\n",
    "            db = pickle.load(database)   \n",
    "            \n",
    "            if name in db or name == 'unknown':\n",
    "                print(\"Name Already Exists! Try Another Name...\")\n",
    "                return\n",
    "    else:\n",
    "        #if database not exists than creating new database\n",
    "        db = {}\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(3, 640)\n",
    "    cap.set(4, 480)\n",
    "    \n",
    "    #detecting only frontal face using haarcascade\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "    \n",
    "    i = 3\n",
    "    face_found = False\n",
    "    \n",
    "    while True:            \n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "            \n",
    "        #time.sleep(1.0)\n",
    "        cv2.putText(frame, 'Keep Your Face infront of Camera', (100, 200), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, 'Starting', (260, 270), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    0.8, (255, 255, 255), 2)\n",
    "        \n",
    "        cv2.putText(frame, str(i), (290, 330), cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                    1.3, (255, 255, 255), 3)\n",
    "\n",
    "        i-=1\n",
    "                   \n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(1000)\n",
    "        \n",
    "        if i < 0:\n",
    "            break\n",
    "            \n",
    "    start_time = time.time()        \n",
    "    img_path = './saved_image/1.jpg'\n",
    "\n",
    "    ## Face recognition \n",
    "    while True:\n",
    "        curr_time = time.time()\n",
    "        \n",
    "        _, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1, 0)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        face = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        \n",
    "        if len(face) == 1:\n",
    "            for(x, y, w, h) in face:\n",
    "                roi = frame[y-10:y+h+10, x-10:x+w+10]\n",
    "\n",
    "                fh, fw = roi.shape[:2]\n",
    "\n",
    "                #make sure the face roi is of required height and width\n",
    "                if fh < 20 and fw < 20:\n",
    "                    continue\n",
    "\n",
    "                face_found = True\n",
    "                #cv2.imwrite(img_path, roi)\n",
    "\n",
    "                cv2.rectangle(frame, (x-10,y-10), (x+w+10, y+h+10), (255, 200, 200), 2)\n",
    "\n",
    "         \n",
    "        if curr_time - start_time >= 3:\n",
    "            break\n",
    "            \n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(1)\n",
    "            \n",
    "    cap.release()        \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    \n",
    "    if face_found:\n",
    "        img = cv2.resize(roi, (96, 96))\n",
    "\n",
    "        db[name] = img_to_encoding(img)\n",
    "\n",
    "        with open('embeddings.pickle', \"wb\") as database:\n",
    "            pickle.dump(db, database, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    elif len(face) > 1:\n",
    "        print(\"More than one faces found. Try again...\")\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        print('There was no face found in the frame. Try again...')\n",
    "        return\n",
    "      \n",
    "    os.system('cls' if os.name == 'nt' else 'clear') \n",
    "    \n",
    "    #Voice authentication\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    CHUNK = 1024\n",
    "    RECORD_SECONDS = 3\n",
    "    \n",
    "    source = \"./voice_database/\" + name\n",
    "    \n",
    "   \n",
    "    os.mkdir(source)\n",
    "\n",
    "    for i in range(3):\n",
    "        audio = pyaudio.PyAudio()\n",
    "\n",
    "        if i == 0:\n",
    "            j = 3\n",
    "            while j>=0:\n",
    "                time.sleep(1.0)\n",
    "                os.system('cls' if os.name == 'nt' else 'clear')\n",
    "                print(\"Speak your name in {} seconds\".format(j))\n",
    "                j-=1\n",
    "\n",
    "        elif i ==1:\n",
    "            time.sleep(2.0)\n",
    "            print(\"Speak your name one more time\")\n",
    "            time.sleep(0.8)\n",
    "        \n",
    "        else:\n",
    "            time.sleep(2.0)\n",
    "            print(\"Speak your name one last time\")\n",
    "            time.sleep(0.8)\n",
    "\n",
    "        # start Recording\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                    rate=RATE, input=True,\n",
    "                    frames_per_buffer=CHUNK)\n",
    "\n",
    "        print(\"recording...\")\n",
    "        frames = []\n",
    "\n",
    "        for _ in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            frames.append(data)\n",
    "\n",
    "        # stop Recording\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "        \n",
    "        # saving wav file of speaker\n",
    "        waveFile = wave.open(source + '/' + str((i+1)) + '.wav', 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(frames))\n",
    "        waveFile.close()\n",
    "        print(\"Done\")\n",
    "\n",
    "    dest =  \"./gmm_models/\"\n",
    "    count = 1\n",
    "\n",
    "    for path in os.listdir(source):\n",
    "        path = os.path.join(source, path)\n",
    "\n",
    "        features = np.array([])\n",
    "        \n",
    "        # reading audio files of speaker\n",
    "        (sr, audio) = read(path)\n",
    "        \n",
    "        # extract 40 dimensional MFCC & delta MFCC features\n",
    "        vector   = extract_features(audio,sr)\n",
    "\n",
    "        if features.size == 0:\n",
    "            features = vector\n",
    "        else:\n",
    "            features = np.vstack((features, vector))\n",
    "            \n",
    "        # when features of 3 files of speaker are concatenated, then do model training\n",
    "        if count == 3:    \n",
    "            gmm = mixture.GaussianMixture(n_components = 16, max_iter = 200, covariance_type='diag',n_init = 3)\n",
    "            gmm.fit(features)\n",
    "\n",
    "            # saving the trained gaussian model\n",
    "            pickle.dump(gmm, open(dest + name + '.gmm', 'wb'))\n",
    "            print(name + ' added successfully') \n",
    "            \n",
    "            features = np.asarray(())\n",
    "            count = 0\n",
    "        count = count + 1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    add_user()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
